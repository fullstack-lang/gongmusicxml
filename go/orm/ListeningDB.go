// generated by stacks/gong/go/models/orm_file_per_struct_back_repo.go
package orm

import (
	"database/sql"
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"sort"
	"time"

	"gorm.io/gorm"

	"github.com/tealeg/xlsx/v3"

	"github.com/fullstack-lang/gongmusicxml/go/models"
)

// dummy variable to have the import declaration wihthout compile failure (even if no code needing this import is generated)
var dummy_Listening_sql sql.NullBool
var dummy_Listening_time time.Duration
var dummy_Listening_sort sort.Float64Slice

// ListeningAPI is the input in POST API
//
// for POST, API, one needs the fields of the model as well as the fields
// from associations ("Has One" and "Has Many") that are generated to
// fullfill the ORM requirements for associations
//
// swagger:model listeningAPI
type ListeningAPI struct {
	gorm.Model

	models.Listening_WOP

	// encoding of pointers
	// for API, it cannot be embedded
	ListeningPointersEncoding ListeningPointersEncoding
}

// ListeningPointersEncoding encodes pointers to Struct and
// reverse pointers of slice of poitners to Struct
type ListeningPointersEncoding struct {
	// insertion for pointer fields encoding declaration

	// field Offset is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	OffsetID sql.NullInt64

	// field Sync is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	SyncID sql.NullInt64

	// field Other_listening is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	Other_listeningID sql.NullInt64
}

// ListeningDB describes a listening in the database
//
// It incorporates the GORM ID, basic fields from the model (because they can be serialized),
// the encoded version of pointers
//
// swagger:model listeningDB
type ListeningDB struct {
	gorm.Model

	// insertion for basic fields declaration

	// Declation for basic field listeningDB.Name
	Name_Data sql.NullString
	
	// encoding of pointers
	// for GORM serialization, it is necessary to embed to Pointer Encoding declaration
	ListeningPointersEncoding
}

// ListeningDBs arrays listeningDBs
// swagger:response listeningDBsResponse
type ListeningDBs []ListeningDB

// ListeningDBResponse provides response
// swagger:response listeningDBResponse
type ListeningDBResponse struct {
	ListeningDB
}

// ListeningWOP is a Listening without pointers (WOP is an acronym for "Without Pointers")
// it holds the same basic fields but pointers are encoded into uint
type ListeningWOP struct {
	ID int `xlsx:"0"`

	// insertion for WOP basic fields

	Name string `xlsx:"1"`
	// insertion for WOP pointer fields
}

var Listening_Fields = []string{
	// insertion for WOP basic fields
	"ID",
	"Name",
}

type BackRepoListeningStruct struct {
	// stores ListeningDB according to their gorm ID
	Map_ListeningDBID_ListeningDB map[uint]*ListeningDB

	// stores ListeningDB ID according to Listening address
	Map_ListeningPtr_ListeningDBID map[*models.Listening]uint

	// stores Listening according to their gorm ID
	Map_ListeningDBID_ListeningPtr map[uint]*models.Listening

	db *gorm.DB

	stage *models.StageStruct
}

func (backRepoListening *BackRepoListeningStruct) GetStage() (stage *models.StageStruct) {
	stage = backRepoListening.stage
	return
}

func (backRepoListening *BackRepoListeningStruct) GetDB() *gorm.DB {
	return backRepoListening.db
}

// GetListeningDBFromListeningPtr is a handy function to access the back repo instance from the stage instance
func (backRepoListening *BackRepoListeningStruct) GetListeningDBFromListeningPtr(listening *models.Listening) (listeningDB *ListeningDB) {
	id := backRepoListening.Map_ListeningPtr_ListeningDBID[listening]
	listeningDB = backRepoListening.Map_ListeningDBID_ListeningDB[id]
	return
}

// BackRepoListening.CommitPhaseOne commits all staged instances of Listening to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoListening *BackRepoListeningStruct) CommitPhaseOne(stage *models.StageStruct) (Error error) {

	for listening := range stage.Listenings {
		backRepoListening.CommitPhaseOneInstance(listening)
	}

	// parse all backRepo instance and checks wether some instance have been unstaged
	// in this case, remove them from the back repo
	for id, listening := range backRepoListening.Map_ListeningDBID_ListeningPtr {
		if _, ok := stage.Listenings[listening]; !ok {
			backRepoListening.CommitDeleteInstance(id)
		}
	}

	return
}

// BackRepoListening.CommitDeleteInstance commits deletion of Listening to the BackRepo
func (backRepoListening *BackRepoListeningStruct) CommitDeleteInstance(id uint) (Error error) {

	listening := backRepoListening.Map_ListeningDBID_ListeningPtr[id]

	// listening is not staged anymore, remove listeningDB
	listeningDB := backRepoListening.Map_ListeningDBID_ListeningDB[id]
	query := backRepoListening.db.Unscoped().Delete(&listeningDB)
	if query.Error != nil {
		log.Fatal(query.Error)
	}

	// update stores
	delete(backRepoListening.Map_ListeningPtr_ListeningDBID, listening)
	delete(backRepoListening.Map_ListeningDBID_ListeningPtr, id)
	delete(backRepoListening.Map_ListeningDBID_ListeningDB, id)

	return
}

// BackRepoListening.CommitPhaseOneInstance commits listening staged instances of Listening to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoListening *BackRepoListeningStruct) CommitPhaseOneInstance(listening *models.Listening) (Error error) {

	// check if the listening is not commited yet
	if _, ok := backRepoListening.Map_ListeningPtr_ListeningDBID[listening]; ok {
		return
	}

	// initiate listening
	var listeningDB ListeningDB
	listeningDB.CopyBasicFieldsFromListening(listening)

	query := backRepoListening.db.Create(&listeningDB)
	if query.Error != nil {
		log.Fatal(query.Error)
	}

	// update stores
	backRepoListening.Map_ListeningPtr_ListeningDBID[listening] = listeningDB.ID
	backRepoListening.Map_ListeningDBID_ListeningPtr[listeningDB.ID] = listening
	backRepoListening.Map_ListeningDBID_ListeningDB[listeningDB.ID] = &listeningDB

	return
}

// BackRepoListening.CommitPhaseTwo commits all staged instances of Listening to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoListening *BackRepoListeningStruct) CommitPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	for idx, listening := range backRepoListening.Map_ListeningDBID_ListeningPtr {
		backRepoListening.CommitPhaseTwoInstance(backRepo, idx, listening)
	}

	return
}

// BackRepoListening.CommitPhaseTwoInstance commits {{structname }} of models.Listening to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoListening *BackRepoListeningStruct) CommitPhaseTwoInstance(backRepo *BackRepoStruct, idx uint, listening *models.Listening) (Error error) {

	// fetch matching listeningDB
	if listeningDB, ok := backRepoListening.Map_ListeningDBID_ListeningDB[idx]; ok {

		listeningDB.CopyBasicFieldsFromListening(listening)

		// insertion point for translating pointers encodings into actual pointers
		// commit pointer value listening.Offset translates to updating the listening.OffsetID
		listeningDB.OffsetID.Valid = true // allow for a 0 value (nil association)
		if listening.Offset != nil {
			if OffsetId, ok := backRepo.BackRepoOffset.Map_OffsetPtr_OffsetDBID[listening.Offset]; ok {
				listeningDB.OffsetID.Int64 = int64(OffsetId)
				listeningDB.OffsetID.Valid = true
			}
		} else {
			listeningDB.OffsetID.Int64 = 0
			listeningDB.OffsetID.Valid = true
		}

		// commit pointer value listening.Sync translates to updating the listening.SyncID
		listeningDB.SyncID.Valid = true // allow for a 0 value (nil association)
		if listening.Sync != nil {
			if SyncId, ok := backRepo.BackRepoSync.Map_SyncPtr_SyncDBID[listening.Sync]; ok {
				listeningDB.SyncID.Int64 = int64(SyncId)
				listeningDB.SyncID.Valid = true
			}
		} else {
			listeningDB.SyncID.Int64 = 0
			listeningDB.SyncID.Valid = true
		}

		// commit pointer value listening.Other_listening translates to updating the listening.Other_listeningID
		listeningDB.Other_listeningID.Valid = true // allow for a 0 value (nil association)
		if listening.Other_listening != nil {
			if Other_listeningId, ok := backRepo.BackRepoOther_listening.Map_Other_listeningPtr_Other_listeningDBID[listening.Other_listening]; ok {
				listeningDB.Other_listeningID.Int64 = int64(Other_listeningId)
				listeningDB.Other_listeningID.Valid = true
			}
		} else {
			listeningDB.Other_listeningID.Int64 = 0
			listeningDB.Other_listeningID.Valid = true
		}

		query := backRepoListening.db.Save(&listeningDB)
		if query.Error != nil {
			log.Fatalln(query.Error)
		}

	} else {
		err := errors.New(
			fmt.Sprintf("Unkown Listening intance %s", listening.Name))
		return err
	}

	return
}

// BackRepoListening.CheckoutPhaseOne Checkouts all BackRepo instances to the Stage
//
// Phase One will result in having instances on the stage aligned with the back repo
// pointers are not initialized yet (this is for phase two)
func (backRepoListening *BackRepoListeningStruct) CheckoutPhaseOne() (Error error) {

	listeningDBArray := make([]ListeningDB, 0)
	query := backRepoListening.db.Find(&listeningDBArray)
	if query.Error != nil {
		return query.Error
	}

	// list of instances to be removed
	// start from the initial map on the stage and remove instances that have been checked out
	listeningInstancesToBeRemovedFromTheStage := make(map[*models.Listening]any)
	for key, value := range backRepoListening.stage.Listenings {
		listeningInstancesToBeRemovedFromTheStage[key] = value
	}

	// copy orm objects to the the map
	for _, listeningDB := range listeningDBArray {
		backRepoListening.CheckoutPhaseOneInstance(&listeningDB)

		// do not remove this instance from the stage, therefore
		// remove instance from the list of instances to be be removed from the stage
		listening, ok := backRepoListening.Map_ListeningDBID_ListeningPtr[listeningDB.ID]
		if ok {
			delete(listeningInstancesToBeRemovedFromTheStage, listening)
		}
	}

	// remove from stage and back repo's 3 maps all listenings that are not in the checkout
	for listening := range listeningInstancesToBeRemovedFromTheStage {
		listening.Unstage(backRepoListening.GetStage())

		// remove instance from the back repo 3 maps
		listeningID := backRepoListening.Map_ListeningPtr_ListeningDBID[listening]
		delete(backRepoListening.Map_ListeningPtr_ListeningDBID, listening)
		delete(backRepoListening.Map_ListeningDBID_ListeningDB, listeningID)
		delete(backRepoListening.Map_ListeningDBID_ListeningPtr, listeningID)
	}

	return
}

// CheckoutPhaseOneInstance takes a listeningDB that has been found in the DB, updates the backRepo and stages the
// models version of the listeningDB
func (backRepoListening *BackRepoListeningStruct) CheckoutPhaseOneInstance(listeningDB *ListeningDB) (Error error) {

	listening, ok := backRepoListening.Map_ListeningDBID_ListeningPtr[listeningDB.ID]
	if !ok {
		listening = new(models.Listening)

		backRepoListening.Map_ListeningDBID_ListeningPtr[listeningDB.ID] = listening
		backRepoListening.Map_ListeningPtr_ListeningDBID[listening] = listeningDB.ID

		// append model store with the new element
		listening.Name = listeningDB.Name_Data.String
		listening.Stage(backRepoListening.GetStage())
	}
	listeningDB.CopyBasicFieldsToListening(listening)

	// in some cases, the instance might have been unstaged. It is necessary to stage it again
	listening.Stage(backRepoListening.GetStage())

	// preserve pointer to listeningDB. Otherwise, pointer will is recycled and the map of pointers
	// Map_ListeningDBID_ListeningDB)[listeningDB hold variable pointers
	listeningDB_Data := *listeningDB
	preservedPtrToListening := &listeningDB_Data
	backRepoListening.Map_ListeningDBID_ListeningDB[listeningDB.ID] = preservedPtrToListening

	return
}

// BackRepoListening.CheckoutPhaseTwo Checkouts all staged instances of Listening to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoListening *BackRepoListeningStruct) CheckoutPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	// parse all DB instance and update all pointer fields of the translated models instance
	for _, listeningDB := range backRepoListening.Map_ListeningDBID_ListeningDB {
		backRepoListening.CheckoutPhaseTwoInstance(backRepo, listeningDB)
	}
	return
}

// BackRepoListening.CheckoutPhaseTwoInstance Checkouts staged instances of Listening to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoListening *BackRepoListeningStruct) CheckoutPhaseTwoInstance(backRepo *BackRepoStruct, listeningDB *ListeningDB) (Error error) {

	listening := backRepoListening.Map_ListeningDBID_ListeningPtr[listeningDB.ID]

	listeningDB.DecodePointers(backRepo, listening)

	return
}

func (listeningDB *ListeningDB) DecodePointers(backRepo *BackRepoStruct, listening *models.Listening) {

	// insertion point for checkout of pointer encoding
	// Offset field
	listening.Offset = nil
	if listeningDB.OffsetID.Int64 != 0 {
		listening.Offset = backRepo.BackRepoOffset.Map_OffsetDBID_OffsetPtr[uint(listeningDB.OffsetID.Int64)]
	}
	// Sync field
	listening.Sync = nil
	if listeningDB.SyncID.Int64 != 0 {
		listening.Sync = backRepo.BackRepoSync.Map_SyncDBID_SyncPtr[uint(listeningDB.SyncID.Int64)]
	}
	// Other_listening field
	listening.Other_listening = nil
	if listeningDB.Other_listeningID.Int64 != 0 {
		listening.Other_listening = backRepo.BackRepoOther_listening.Map_Other_listeningDBID_Other_listeningPtr[uint(listeningDB.Other_listeningID.Int64)]
	}
	return
}

// CommitListening allows commit of a single listening (if already staged)
func (backRepo *BackRepoStruct) CommitListening(listening *models.Listening) {
	backRepo.BackRepoListening.CommitPhaseOneInstance(listening)
	if id, ok := backRepo.BackRepoListening.Map_ListeningPtr_ListeningDBID[listening]; ok {
		backRepo.BackRepoListening.CommitPhaseTwoInstance(backRepo, id, listening)
	}
	backRepo.CommitFromBackNb = backRepo.CommitFromBackNb + 1
}

// CommitListening allows checkout of a single listening (if already staged and with a BackRepo id)
func (backRepo *BackRepoStruct) CheckoutListening(listening *models.Listening) {
	// check if the listening is staged
	if _, ok := backRepo.BackRepoListening.Map_ListeningPtr_ListeningDBID[listening]; ok {

		if id, ok := backRepo.BackRepoListening.Map_ListeningPtr_ListeningDBID[listening]; ok {
			var listeningDB ListeningDB
			listeningDB.ID = id

			if err := backRepo.BackRepoListening.db.First(&listeningDB, id).Error; err != nil {
				log.Fatalln("CheckoutListening : Problem with getting object with id:", id)
			}
			backRepo.BackRepoListening.CheckoutPhaseOneInstance(&listeningDB)
			backRepo.BackRepoListening.CheckoutPhaseTwoInstance(backRepo, &listeningDB)
		}
	}
}

// CopyBasicFieldsFromListening
func (listeningDB *ListeningDB) CopyBasicFieldsFromListening(listening *models.Listening) {
	// insertion point for fields commit

	listeningDB.Name_Data.String = listening.Name
	listeningDB.Name_Data.Valid = true
}

// CopyBasicFieldsFromListening_WOP
func (listeningDB *ListeningDB) CopyBasicFieldsFromListening_WOP(listening *models.Listening_WOP) {
	// insertion point for fields commit

	listeningDB.Name_Data.String = listening.Name
	listeningDB.Name_Data.Valid = true
}

// CopyBasicFieldsFromListeningWOP
func (listeningDB *ListeningDB) CopyBasicFieldsFromListeningWOP(listening *ListeningWOP) {
	// insertion point for fields commit

	listeningDB.Name_Data.String = listening.Name
	listeningDB.Name_Data.Valid = true
}

// CopyBasicFieldsToListening
func (listeningDB *ListeningDB) CopyBasicFieldsToListening(listening *models.Listening) {
	// insertion point for checkout of basic fields (back repo to stage)
	listening.Name = listeningDB.Name_Data.String
}

// CopyBasicFieldsToListening_WOP
func (listeningDB *ListeningDB) CopyBasicFieldsToListening_WOP(listening *models.Listening_WOP) {
	// insertion point for checkout of basic fields (back repo to stage)
	listening.Name = listeningDB.Name_Data.String
}

// CopyBasicFieldsToListeningWOP
func (listeningDB *ListeningDB) CopyBasicFieldsToListeningWOP(listening *ListeningWOP) {
	listening.ID = int(listeningDB.ID)
	// insertion point for checkout of basic fields (back repo to stage)
	listening.Name = listeningDB.Name_Data.String
}

// Backup generates a json file from a slice of all ListeningDB instances in the backrepo
func (backRepoListening *BackRepoListeningStruct) Backup(dirPath string) {

	filename := filepath.Join(dirPath, "ListeningDB.json")

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*ListeningDB, 0)
	for _, listeningDB := range backRepoListening.Map_ListeningDBID_ListeningDB {
		forBackup = append(forBackup, listeningDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	file, err := json.MarshalIndent(forBackup, "", " ")

	if err != nil {
		log.Fatal("Cannot json Listening ", filename, " ", err.Error())
	}

	err = ioutil.WriteFile(filename, file, 0644)
	if err != nil {
		log.Fatal("Cannot write the json Listening file", err.Error())
	}
}

// Backup generates a json file from a slice of all ListeningDB instances in the backrepo
func (backRepoListening *BackRepoListeningStruct) BackupXL(file *xlsx.File) {

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*ListeningDB, 0)
	for _, listeningDB := range backRepoListening.Map_ListeningDBID_ListeningDB {
		forBackup = append(forBackup, listeningDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	sh, err := file.AddSheet("Listening")
	if err != nil {
		log.Fatal("Cannot add XL file", err.Error())
	}
	_ = sh

	row := sh.AddRow()
	row.WriteSlice(&Listening_Fields, -1)
	for _, listeningDB := range forBackup {

		var listeningWOP ListeningWOP
		listeningDB.CopyBasicFieldsToListeningWOP(&listeningWOP)

		row := sh.AddRow()
		row.WriteStruct(&listeningWOP, -1)
	}
}

// RestoreXL from the "Listening" sheet all ListeningDB instances
func (backRepoListening *BackRepoListeningStruct) RestoreXLPhaseOne(file *xlsx.File) {

	// resets the map
	BackRepoListeningid_atBckpTime_newID = make(map[uint]uint)

	sh, ok := file.Sheet["Listening"]
	_ = sh
	if !ok {
		log.Fatal(errors.New("sheet not found"))
	}

	// log.Println("Max row is", sh.MaxRow)
	err := sh.ForEachRow(backRepoListening.rowVisitorListening)
	if err != nil {
		log.Fatal("Err=", err)
	}
}

func (backRepoListening *BackRepoListeningStruct) rowVisitorListening(row *xlsx.Row) error {

	log.Printf("row line %d\n", row.GetCoordinate())
	log.Println(row)

	// skip first line
	if row.GetCoordinate() > 0 {
		var listeningWOP ListeningWOP
		row.ReadStruct(&listeningWOP)

		// add the unmarshalled struct to the stage
		listeningDB := new(ListeningDB)
		listeningDB.CopyBasicFieldsFromListeningWOP(&listeningWOP)

		listeningDB_ID_atBackupTime := listeningDB.ID
		listeningDB.ID = 0
		query := backRepoListening.db.Create(listeningDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
		backRepoListening.Map_ListeningDBID_ListeningDB[listeningDB.ID] = listeningDB
		BackRepoListeningid_atBckpTime_newID[listeningDB_ID_atBackupTime] = listeningDB.ID
	}
	return nil
}

// RestorePhaseOne read the file "ListeningDB.json" in dirPath that stores an array
// of ListeningDB and stores it in the database
// the map BackRepoListeningid_atBckpTime_newID is updated accordingly
func (backRepoListening *BackRepoListeningStruct) RestorePhaseOne(dirPath string) {

	// resets the map
	BackRepoListeningid_atBckpTime_newID = make(map[uint]uint)

	filename := filepath.Join(dirPath, "ListeningDB.json")
	jsonFile, err := os.Open(filename)
	// if we os.Open returns an error then handle it
	if err != nil {
		log.Fatal("Cannot restore/open the json Listening file", filename, " ", err.Error())
	}

	// read our opened jsonFile as a byte array.
	byteValue, _ := ioutil.ReadAll(jsonFile)

	var forRestore []*ListeningDB

	err = json.Unmarshal(byteValue, &forRestore)

	// fill up Map_ListeningDBID_ListeningDB
	for _, listeningDB := range forRestore {

		listeningDB_ID_atBackupTime := listeningDB.ID
		listeningDB.ID = 0
		query := backRepoListening.db.Create(listeningDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
		backRepoListening.Map_ListeningDBID_ListeningDB[listeningDB.ID] = listeningDB
		BackRepoListeningid_atBckpTime_newID[listeningDB_ID_atBackupTime] = listeningDB.ID
	}

	if err != nil {
		log.Fatal("Cannot restore/unmarshall json Listening file", err.Error())
	}
}

// RestorePhaseTwo uses all map BackRepo<Listening>id_atBckpTime_newID
// to compute new index
func (backRepoListening *BackRepoListeningStruct) RestorePhaseTwo() {

	for _, listeningDB := range backRepoListening.Map_ListeningDBID_ListeningDB {

		// next line of code is to avert unused variable compilation error
		_ = listeningDB

		// insertion point for reindexing pointers encoding
		// reindexing Offset field
		if listeningDB.OffsetID.Int64 != 0 {
			listeningDB.OffsetID.Int64 = int64(BackRepoOffsetid_atBckpTime_newID[uint(listeningDB.OffsetID.Int64)])
			listeningDB.OffsetID.Valid = true
		}

		// reindexing Sync field
		if listeningDB.SyncID.Int64 != 0 {
			listeningDB.SyncID.Int64 = int64(BackRepoSyncid_atBckpTime_newID[uint(listeningDB.SyncID.Int64)])
			listeningDB.SyncID.Valid = true
		}

		// reindexing Other_listening field
		if listeningDB.Other_listeningID.Int64 != 0 {
			listeningDB.Other_listeningID.Int64 = int64(BackRepoOther_listeningid_atBckpTime_newID[uint(listeningDB.Other_listeningID.Int64)])
			listeningDB.Other_listeningID.Valid = true
		}

		// update databse with new index encoding
		query := backRepoListening.db.Model(listeningDB).Updates(*listeningDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
	}

}

// BackRepoListening.ResetReversePointers commits all staged instances of Listening to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoListening *BackRepoListeningStruct) ResetReversePointers(backRepo *BackRepoStruct) (Error error) {

	for idx, listening := range backRepoListening.Map_ListeningDBID_ListeningPtr {
		backRepoListening.ResetReversePointersInstance(backRepo, idx, listening)
	}

	return
}

func (backRepoListening *BackRepoListeningStruct) ResetReversePointersInstance(backRepo *BackRepoStruct, idx uint, listening *models.Listening) (Error error) {

	// fetch matching listeningDB
	if listeningDB, ok := backRepoListening.Map_ListeningDBID_ListeningDB[idx]; ok {
		_ = listeningDB // to avoid unused variable error if there are no reverse to reset

		// insertion point for reverse pointers reset
		// end of insertion point for reverse pointers reset
	}

	return
}

// this field is used during the restauration process.
// it stores the ID at the backup time and is used for renumbering
var BackRepoListeningid_atBckpTime_newID map[uint]uint
