// generated by stacks/gong/go/models/orm_file_per_struct_back_repo.go
package orm

import (
	"database/sql"
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"sort"
	"time"

	"gorm.io/gorm"

	"github.com/tealeg/xlsx/v3"

	"github.com/fullstack-lang/gongmusicxml/go/models"
)

// dummy variable to have the import declaration wihthout compile failure (even if no code needing this import is generated)
var dummy_Defaults_sql sql.NullBool
var dummy_Defaults_time time.Duration
var dummy_Defaults_sort sort.Float64Slice

// DefaultsAPI is the input in POST API
//
// for POST, API, one needs the fields of the model as well as the fields
// from associations ("Has One" and "Has Many") that are generated to
// fullfill the ORM requirements for associations
//
// swagger:model defaultsAPI
type DefaultsAPI struct {
	gorm.Model

	models.Defaults_WOP

	// encoding of pointers
	// for API, it cannot be embedded
	DefaultsPointersEncoding DefaultsPointersEncoding
}

// DefaultsPointersEncoding encodes pointers to Struct and
// reverse pointers of slice of poitners to Struct
type DefaultsPointersEncoding struct {
	// insertion for pointer fields encoding declaration

	// field Scaling is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	ScalingID sql.NullInt64

	// field Concert_score is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	Concert_scoreID sql.NullInt64

	// field Appearance is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	AppearanceID sql.NullInt64

	// field Music_font is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	Music_fontID sql.NullInt64

	// field Word_font is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	Word_fontID sql.NullInt64

	// field Lyric_font is a slice of pointers to another Struct (optional or 0..1)
	Lyric_font IntSlice `gorm:"type:TEXT"`

	// field Lyric_language is a slice of pointers to another Struct (optional or 0..1)
	Lyric_language IntSlice `gorm:"type:TEXT"`
}

// DefaultsDB describes a defaults in the database
//
// It incorporates the GORM ID, basic fields from the model (because they can be serialized),
// the encoded version of pointers
//
// swagger:model defaultsDB
type DefaultsDB struct {
	gorm.Model

	// insertion for basic fields declaration

	// Declation for basic field defaultsDB.Name
	Name_Data sql.NullString
	
	// encoding of pointers
	// for GORM serialization, it is necessary to embed to Pointer Encoding declaration
	DefaultsPointersEncoding
}

// DefaultsDBs arrays defaultsDBs
// swagger:response defaultsDBsResponse
type DefaultsDBs []DefaultsDB

// DefaultsDBResponse provides response
// swagger:response defaultsDBResponse
type DefaultsDBResponse struct {
	DefaultsDB
}

// DefaultsWOP is a Defaults without pointers (WOP is an acronym for "Without Pointers")
// it holds the same basic fields but pointers are encoded into uint
type DefaultsWOP struct {
	ID int `xlsx:"0"`

	// insertion for WOP basic fields

	Name string `xlsx:"1"`
	// insertion for WOP pointer fields
}

var Defaults_Fields = []string{
	// insertion for WOP basic fields
	"ID",
	"Name",
}

type BackRepoDefaultsStruct struct {
	// stores DefaultsDB according to their gorm ID
	Map_DefaultsDBID_DefaultsDB map[uint]*DefaultsDB

	// stores DefaultsDB ID according to Defaults address
	Map_DefaultsPtr_DefaultsDBID map[*models.Defaults]uint

	// stores Defaults according to their gorm ID
	Map_DefaultsDBID_DefaultsPtr map[uint]*models.Defaults

	db *gorm.DB

	stage *models.StageStruct
}

func (backRepoDefaults *BackRepoDefaultsStruct) GetStage() (stage *models.StageStruct) {
	stage = backRepoDefaults.stage
	return
}

func (backRepoDefaults *BackRepoDefaultsStruct) GetDB() *gorm.DB {
	return backRepoDefaults.db
}

// GetDefaultsDBFromDefaultsPtr is a handy function to access the back repo instance from the stage instance
func (backRepoDefaults *BackRepoDefaultsStruct) GetDefaultsDBFromDefaultsPtr(defaults *models.Defaults) (defaultsDB *DefaultsDB) {
	id := backRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults]
	defaultsDB = backRepoDefaults.Map_DefaultsDBID_DefaultsDB[id]
	return
}

// BackRepoDefaults.CommitPhaseOne commits all staged instances of Defaults to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoDefaults *BackRepoDefaultsStruct) CommitPhaseOne(stage *models.StageStruct) (Error error) {

	for defaults := range stage.Defaultss {
		backRepoDefaults.CommitPhaseOneInstance(defaults)
	}

	// parse all backRepo instance and checks wether some instance have been unstaged
	// in this case, remove them from the back repo
	for id, defaults := range backRepoDefaults.Map_DefaultsDBID_DefaultsPtr {
		if _, ok := stage.Defaultss[defaults]; !ok {
			backRepoDefaults.CommitDeleteInstance(id)
		}
	}

	return
}

// BackRepoDefaults.CommitDeleteInstance commits deletion of Defaults to the BackRepo
func (backRepoDefaults *BackRepoDefaultsStruct) CommitDeleteInstance(id uint) (Error error) {

	defaults := backRepoDefaults.Map_DefaultsDBID_DefaultsPtr[id]

	// defaults is not staged anymore, remove defaultsDB
	defaultsDB := backRepoDefaults.Map_DefaultsDBID_DefaultsDB[id]
	query := backRepoDefaults.db.Unscoped().Delete(&defaultsDB)
	if query.Error != nil {
		log.Fatal(query.Error)
	}

	// update stores
	delete(backRepoDefaults.Map_DefaultsPtr_DefaultsDBID, defaults)
	delete(backRepoDefaults.Map_DefaultsDBID_DefaultsPtr, id)
	delete(backRepoDefaults.Map_DefaultsDBID_DefaultsDB, id)

	return
}

// BackRepoDefaults.CommitPhaseOneInstance commits defaults staged instances of Defaults to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoDefaults *BackRepoDefaultsStruct) CommitPhaseOneInstance(defaults *models.Defaults) (Error error) {

	// check if the defaults is not commited yet
	if _, ok := backRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults]; ok {
		return
	}

	// initiate defaults
	var defaultsDB DefaultsDB
	defaultsDB.CopyBasicFieldsFromDefaults(defaults)

	query := backRepoDefaults.db.Create(&defaultsDB)
	if query.Error != nil {
		log.Fatal(query.Error)
	}

	// update stores
	backRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults] = defaultsDB.ID
	backRepoDefaults.Map_DefaultsDBID_DefaultsPtr[defaultsDB.ID] = defaults
	backRepoDefaults.Map_DefaultsDBID_DefaultsDB[defaultsDB.ID] = &defaultsDB

	return
}

// BackRepoDefaults.CommitPhaseTwo commits all staged instances of Defaults to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoDefaults *BackRepoDefaultsStruct) CommitPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	for idx, defaults := range backRepoDefaults.Map_DefaultsDBID_DefaultsPtr {
		backRepoDefaults.CommitPhaseTwoInstance(backRepo, idx, defaults)
	}

	return
}

// BackRepoDefaults.CommitPhaseTwoInstance commits {{structname }} of models.Defaults to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoDefaults *BackRepoDefaultsStruct) CommitPhaseTwoInstance(backRepo *BackRepoStruct, idx uint, defaults *models.Defaults) (Error error) {

	// fetch matching defaultsDB
	if defaultsDB, ok := backRepoDefaults.Map_DefaultsDBID_DefaultsDB[idx]; ok {

		defaultsDB.CopyBasicFieldsFromDefaults(defaults)

		// insertion point for translating pointers encodings into actual pointers
		// commit pointer value defaults.Scaling translates to updating the defaults.ScalingID
		defaultsDB.ScalingID.Valid = true // allow for a 0 value (nil association)
		if defaults.Scaling != nil {
			if ScalingId, ok := backRepo.BackRepoScaling.Map_ScalingPtr_ScalingDBID[defaults.Scaling]; ok {
				defaultsDB.ScalingID.Int64 = int64(ScalingId)
				defaultsDB.ScalingID.Valid = true
			}
		} else {
			defaultsDB.ScalingID.Int64 = 0
			defaultsDB.ScalingID.Valid = true
		}

		// commit pointer value defaults.Concert_score translates to updating the defaults.Concert_scoreID
		defaultsDB.Concert_scoreID.Valid = true // allow for a 0 value (nil association)
		if defaults.Concert_score != nil {
			if Concert_scoreId, ok := backRepo.BackRepoEmpty.Map_EmptyPtr_EmptyDBID[defaults.Concert_score]; ok {
				defaultsDB.Concert_scoreID.Int64 = int64(Concert_scoreId)
				defaultsDB.Concert_scoreID.Valid = true
			}
		} else {
			defaultsDB.Concert_scoreID.Int64 = 0
			defaultsDB.Concert_scoreID.Valid = true
		}

		// commit pointer value defaults.Appearance translates to updating the defaults.AppearanceID
		defaultsDB.AppearanceID.Valid = true // allow for a 0 value (nil association)
		if defaults.Appearance != nil {
			if AppearanceId, ok := backRepo.BackRepoAppearance.Map_AppearancePtr_AppearanceDBID[defaults.Appearance]; ok {
				defaultsDB.AppearanceID.Int64 = int64(AppearanceId)
				defaultsDB.AppearanceID.Valid = true
			}
		} else {
			defaultsDB.AppearanceID.Int64 = 0
			defaultsDB.AppearanceID.Valid = true
		}

		// commit pointer value defaults.Music_font translates to updating the defaults.Music_fontID
		defaultsDB.Music_fontID.Valid = true // allow for a 0 value (nil association)
		if defaults.Music_font != nil {
			if Music_fontId, ok := backRepo.BackRepoEmpty_font.Map_Empty_fontPtr_Empty_fontDBID[defaults.Music_font]; ok {
				defaultsDB.Music_fontID.Int64 = int64(Music_fontId)
				defaultsDB.Music_fontID.Valid = true
			}
		} else {
			defaultsDB.Music_fontID.Int64 = 0
			defaultsDB.Music_fontID.Valid = true
		}

		// commit pointer value defaults.Word_font translates to updating the defaults.Word_fontID
		defaultsDB.Word_fontID.Valid = true // allow for a 0 value (nil association)
		if defaults.Word_font != nil {
			if Word_fontId, ok := backRepo.BackRepoEmpty_font.Map_Empty_fontPtr_Empty_fontDBID[defaults.Word_font]; ok {
				defaultsDB.Word_fontID.Int64 = int64(Word_fontId)
				defaultsDB.Word_fontID.Valid = true
			}
		} else {
			defaultsDB.Word_fontID.Int64 = 0
			defaultsDB.Word_fontID.Valid = true
		}

		// 1. reset
		defaultsDB.DefaultsPointersEncoding.Lyric_font = make([]int, 0)
		// 2. encode
		for _, lyric_fontAssocEnd := range defaults.Lyric_font {
			lyric_fontAssocEnd_DB :=
				backRepo.BackRepoLyric_font.GetLyric_fontDBFromLyric_fontPtr(lyric_fontAssocEnd)
			
			// the stage might be inconsistant, meaning that the lyric_fontAssocEnd_DB might
			// be missing from the stage. In this case, the commit operation is robust
			// An alternative would be to crash here to reveal the missing element.
			if lyric_fontAssocEnd_DB == nil {
				continue
			}
			
			defaultsDB.DefaultsPointersEncoding.Lyric_font =
				append(defaultsDB.DefaultsPointersEncoding.Lyric_font, int(lyric_fontAssocEnd_DB.ID))
		}

		// 1. reset
		defaultsDB.DefaultsPointersEncoding.Lyric_language = make([]int, 0)
		// 2. encode
		for _, lyric_languageAssocEnd := range defaults.Lyric_language {
			lyric_languageAssocEnd_DB :=
				backRepo.BackRepoLyric_language.GetLyric_languageDBFromLyric_languagePtr(lyric_languageAssocEnd)
			
			// the stage might be inconsistant, meaning that the lyric_languageAssocEnd_DB might
			// be missing from the stage. In this case, the commit operation is robust
			// An alternative would be to crash here to reveal the missing element.
			if lyric_languageAssocEnd_DB == nil {
				continue
			}
			
			defaultsDB.DefaultsPointersEncoding.Lyric_language =
				append(defaultsDB.DefaultsPointersEncoding.Lyric_language, int(lyric_languageAssocEnd_DB.ID))
		}

		query := backRepoDefaults.db.Save(&defaultsDB)
		if query.Error != nil {
			log.Fatalln(query.Error)
		}

	} else {
		err := errors.New(
			fmt.Sprintf("Unkown Defaults intance %s", defaults.Name))
		return err
	}

	return
}

// BackRepoDefaults.CheckoutPhaseOne Checkouts all BackRepo instances to the Stage
//
// Phase One will result in having instances on the stage aligned with the back repo
// pointers are not initialized yet (this is for phase two)
func (backRepoDefaults *BackRepoDefaultsStruct) CheckoutPhaseOne() (Error error) {

	defaultsDBArray := make([]DefaultsDB, 0)
	query := backRepoDefaults.db.Find(&defaultsDBArray)
	if query.Error != nil {
		return query.Error
	}

	// list of instances to be removed
	// start from the initial map on the stage and remove instances that have been checked out
	defaultsInstancesToBeRemovedFromTheStage := make(map[*models.Defaults]any)
	for key, value := range backRepoDefaults.stage.Defaultss {
		defaultsInstancesToBeRemovedFromTheStage[key] = value
	}

	// copy orm objects to the the map
	for _, defaultsDB := range defaultsDBArray {
		backRepoDefaults.CheckoutPhaseOneInstance(&defaultsDB)

		// do not remove this instance from the stage, therefore
		// remove instance from the list of instances to be be removed from the stage
		defaults, ok := backRepoDefaults.Map_DefaultsDBID_DefaultsPtr[defaultsDB.ID]
		if ok {
			delete(defaultsInstancesToBeRemovedFromTheStage, defaults)
		}
	}

	// remove from stage and back repo's 3 maps all defaultss that are not in the checkout
	for defaults := range defaultsInstancesToBeRemovedFromTheStage {
		defaults.Unstage(backRepoDefaults.GetStage())

		// remove instance from the back repo 3 maps
		defaultsID := backRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults]
		delete(backRepoDefaults.Map_DefaultsPtr_DefaultsDBID, defaults)
		delete(backRepoDefaults.Map_DefaultsDBID_DefaultsDB, defaultsID)
		delete(backRepoDefaults.Map_DefaultsDBID_DefaultsPtr, defaultsID)
	}

	return
}

// CheckoutPhaseOneInstance takes a defaultsDB that has been found in the DB, updates the backRepo and stages the
// models version of the defaultsDB
func (backRepoDefaults *BackRepoDefaultsStruct) CheckoutPhaseOneInstance(defaultsDB *DefaultsDB) (Error error) {

	defaults, ok := backRepoDefaults.Map_DefaultsDBID_DefaultsPtr[defaultsDB.ID]
	if !ok {
		defaults = new(models.Defaults)

		backRepoDefaults.Map_DefaultsDBID_DefaultsPtr[defaultsDB.ID] = defaults
		backRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults] = defaultsDB.ID

		// append model store with the new element
		defaults.Name = defaultsDB.Name_Data.String
		defaults.Stage(backRepoDefaults.GetStage())
	}
	defaultsDB.CopyBasicFieldsToDefaults(defaults)

	// in some cases, the instance might have been unstaged. It is necessary to stage it again
	defaults.Stage(backRepoDefaults.GetStage())

	// preserve pointer to defaultsDB. Otherwise, pointer will is recycled and the map of pointers
	// Map_DefaultsDBID_DefaultsDB)[defaultsDB hold variable pointers
	defaultsDB_Data := *defaultsDB
	preservedPtrToDefaults := &defaultsDB_Data
	backRepoDefaults.Map_DefaultsDBID_DefaultsDB[defaultsDB.ID] = preservedPtrToDefaults

	return
}

// BackRepoDefaults.CheckoutPhaseTwo Checkouts all staged instances of Defaults to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoDefaults *BackRepoDefaultsStruct) CheckoutPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	// parse all DB instance and update all pointer fields of the translated models instance
	for _, defaultsDB := range backRepoDefaults.Map_DefaultsDBID_DefaultsDB {
		backRepoDefaults.CheckoutPhaseTwoInstance(backRepo, defaultsDB)
	}
	return
}

// BackRepoDefaults.CheckoutPhaseTwoInstance Checkouts staged instances of Defaults to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoDefaults *BackRepoDefaultsStruct) CheckoutPhaseTwoInstance(backRepo *BackRepoStruct, defaultsDB *DefaultsDB) (Error error) {

	defaults := backRepoDefaults.Map_DefaultsDBID_DefaultsPtr[defaultsDB.ID]

	defaultsDB.DecodePointers(backRepo, defaults)

	return
}

func (defaultsDB *DefaultsDB) DecodePointers(backRepo *BackRepoStruct, defaults *models.Defaults) {

	// insertion point for checkout of pointer encoding
	// Scaling field
	defaults.Scaling = nil
	if defaultsDB.ScalingID.Int64 != 0 {
		defaults.Scaling = backRepo.BackRepoScaling.Map_ScalingDBID_ScalingPtr[uint(defaultsDB.ScalingID.Int64)]
	}
	// Concert_score field
	defaults.Concert_score = nil
	if defaultsDB.Concert_scoreID.Int64 != 0 {
		defaults.Concert_score = backRepo.BackRepoEmpty.Map_EmptyDBID_EmptyPtr[uint(defaultsDB.Concert_scoreID.Int64)]
	}
	// Appearance field
	defaults.Appearance = nil
	if defaultsDB.AppearanceID.Int64 != 0 {
		defaults.Appearance = backRepo.BackRepoAppearance.Map_AppearanceDBID_AppearancePtr[uint(defaultsDB.AppearanceID.Int64)]
	}
	// Music_font field
	defaults.Music_font = nil
	if defaultsDB.Music_fontID.Int64 != 0 {
		defaults.Music_font = backRepo.BackRepoEmpty_font.Map_Empty_fontDBID_Empty_fontPtr[uint(defaultsDB.Music_fontID.Int64)]
	}
	// Word_font field
	defaults.Word_font = nil
	if defaultsDB.Word_fontID.Int64 != 0 {
		defaults.Word_font = backRepo.BackRepoEmpty_font.Map_Empty_fontDBID_Empty_fontPtr[uint(defaultsDB.Word_fontID.Int64)]
	}
	// This loop redeem defaults.Lyric_font in the stage from the encode in the back repo
	// It parses all Lyric_fontDB in the back repo and if the reverse pointer encoding matches the back repo ID
	// it appends the stage instance
	// 1. reset the slice
	defaults.Lyric_font = defaults.Lyric_font[:0]
	for _, _Lyric_fontid := range defaultsDB.DefaultsPointersEncoding.Lyric_font {
		defaults.Lyric_font = append(defaults.Lyric_font, backRepo.BackRepoLyric_font.Map_Lyric_fontDBID_Lyric_fontPtr[uint(_Lyric_fontid)])
	}

	// This loop redeem defaults.Lyric_language in the stage from the encode in the back repo
	// It parses all Lyric_languageDB in the back repo and if the reverse pointer encoding matches the back repo ID
	// it appends the stage instance
	// 1. reset the slice
	defaults.Lyric_language = defaults.Lyric_language[:0]
	for _, _Lyric_languageid := range defaultsDB.DefaultsPointersEncoding.Lyric_language {
		defaults.Lyric_language = append(defaults.Lyric_language, backRepo.BackRepoLyric_language.Map_Lyric_languageDBID_Lyric_languagePtr[uint(_Lyric_languageid)])
	}

	return
}

// CommitDefaults allows commit of a single defaults (if already staged)
func (backRepo *BackRepoStruct) CommitDefaults(defaults *models.Defaults) {
	backRepo.BackRepoDefaults.CommitPhaseOneInstance(defaults)
	if id, ok := backRepo.BackRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults]; ok {
		backRepo.BackRepoDefaults.CommitPhaseTwoInstance(backRepo, id, defaults)
	}
	backRepo.CommitFromBackNb = backRepo.CommitFromBackNb + 1
}

// CommitDefaults allows checkout of a single defaults (if already staged and with a BackRepo id)
func (backRepo *BackRepoStruct) CheckoutDefaults(defaults *models.Defaults) {
	// check if the defaults is staged
	if _, ok := backRepo.BackRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults]; ok {

		if id, ok := backRepo.BackRepoDefaults.Map_DefaultsPtr_DefaultsDBID[defaults]; ok {
			var defaultsDB DefaultsDB
			defaultsDB.ID = id

			if err := backRepo.BackRepoDefaults.db.First(&defaultsDB, id).Error; err != nil {
				log.Fatalln("CheckoutDefaults : Problem with getting object with id:", id)
			}
			backRepo.BackRepoDefaults.CheckoutPhaseOneInstance(&defaultsDB)
			backRepo.BackRepoDefaults.CheckoutPhaseTwoInstance(backRepo, &defaultsDB)
		}
	}
}

// CopyBasicFieldsFromDefaults
func (defaultsDB *DefaultsDB) CopyBasicFieldsFromDefaults(defaults *models.Defaults) {
	// insertion point for fields commit

	defaultsDB.Name_Data.String = defaults.Name
	defaultsDB.Name_Data.Valid = true
}

// CopyBasicFieldsFromDefaults_WOP
func (defaultsDB *DefaultsDB) CopyBasicFieldsFromDefaults_WOP(defaults *models.Defaults_WOP) {
	// insertion point for fields commit

	defaultsDB.Name_Data.String = defaults.Name
	defaultsDB.Name_Data.Valid = true
}

// CopyBasicFieldsFromDefaultsWOP
func (defaultsDB *DefaultsDB) CopyBasicFieldsFromDefaultsWOP(defaults *DefaultsWOP) {
	// insertion point for fields commit

	defaultsDB.Name_Data.String = defaults.Name
	defaultsDB.Name_Data.Valid = true
}

// CopyBasicFieldsToDefaults
func (defaultsDB *DefaultsDB) CopyBasicFieldsToDefaults(defaults *models.Defaults) {
	// insertion point for checkout of basic fields (back repo to stage)
	defaults.Name = defaultsDB.Name_Data.String
}

// CopyBasicFieldsToDefaults_WOP
func (defaultsDB *DefaultsDB) CopyBasicFieldsToDefaults_WOP(defaults *models.Defaults_WOP) {
	// insertion point for checkout of basic fields (back repo to stage)
	defaults.Name = defaultsDB.Name_Data.String
}

// CopyBasicFieldsToDefaultsWOP
func (defaultsDB *DefaultsDB) CopyBasicFieldsToDefaultsWOP(defaults *DefaultsWOP) {
	defaults.ID = int(defaultsDB.ID)
	// insertion point for checkout of basic fields (back repo to stage)
	defaults.Name = defaultsDB.Name_Data.String
}

// Backup generates a json file from a slice of all DefaultsDB instances in the backrepo
func (backRepoDefaults *BackRepoDefaultsStruct) Backup(dirPath string) {

	filename := filepath.Join(dirPath, "DefaultsDB.json")

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*DefaultsDB, 0)
	for _, defaultsDB := range backRepoDefaults.Map_DefaultsDBID_DefaultsDB {
		forBackup = append(forBackup, defaultsDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	file, err := json.MarshalIndent(forBackup, "", " ")

	if err != nil {
		log.Fatal("Cannot json Defaults ", filename, " ", err.Error())
	}

	err = ioutil.WriteFile(filename, file, 0644)
	if err != nil {
		log.Fatal("Cannot write the json Defaults file", err.Error())
	}
}

// Backup generates a json file from a slice of all DefaultsDB instances in the backrepo
func (backRepoDefaults *BackRepoDefaultsStruct) BackupXL(file *xlsx.File) {

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*DefaultsDB, 0)
	for _, defaultsDB := range backRepoDefaults.Map_DefaultsDBID_DefaultsDB {
		forBackup = append(forBackup, defaultsDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	sh, err := file.AddSheet("Defaults")
	if err != nil {
		log.Fatal("Cannot add XL file", err.Error())
	}
	_ = sh

	row := sh.AddRow()
	row.WriteSlice(&Defaults_Fields, -1)
	for _, defaultsDB := range forBackup {

		var defaultsWOP DefaultsWOP
		defaultsDB.CopyBasicFieldsToDefaultsWOP(&defaultsWOP)

		row := sh.AddRow()
		row.WriteStruct(&defaultsWOP, -1)
	}
}

// RestoreXL from the "Defaults" sheet all DefaultsDB instances
func (backRepoDefaults *BackRepoDefaultsStruct) RestoreXLPhaseOne(file *xlsx.File) {

	// resets the map
	BackRepoDefaultsid_atBckpTime_newID = make(map[uint]uint)

	sh, ok := file.Sheet["Defaults"]
	_ = sh
	if !ok {
		log.Fatal(errors.New("sheet not found"))
	}

	// log.Println("Max row is", sh.MaxRow)
	err := sh.ForEachRow(backRepoDefaults.rowVisitorDefaults)
	if err != nil {
		log.Fatal("Err=", err)
	}
}

func (backRepoDefaults *BackRepoDefaultsStruct) rowVisitorDefaults(row *xlsx.Row) error {

	log.Printf("row line %d\n", row.GetCoordinate())
	log.Println(row)

	// skip first line
	if row.GetCoordinate() > 0 {
		var defaultsWOP DefaultsWOP
		row.ReadStruct(&defaultsWOP)

		// add the unmarshalled struct to the stage
		defaultsDB := new(DefaultsDB)
		defaultsDB.CopyBasicFieldsFromDefaultsWOP(&defaultsWOP)

		defaultsDB_ID_atBackupTime := defaultsDB.ID
		defaultsDB.ID = 0
		query := backRepoDefaults.db.Create(defaultsDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
		backRepoDefaults.Map_DefaultsDBID_DefaultsDB[defaultsDB.ID] = defaultsDB
		BackRepoDefaultsid_atBckpTime_newID[defaultsDB_ID_atBackupTime] = defaultsDB.ID
	}
	return nil
}

// RestorePhaseOne read the file "DefaultsDB.json" in dirPath that stores an array
// of DefaultsDB and stores it in the database
// the map BackRepoDefaultsid_atBckpTime_newID is updated accordingly
func (backRepoDefaults *BackRepoDefaultsStruct) RestorePhaseOne(dirPath string) {

	// resets the map
	BackRepoDefaultsid_atBckpTime_newID = make(map[uint]uint)

	filename := filepath.Join(dirPath, "DefaultsDB.json")
	jsonFile, err := os.Open(filename)
	// if we os.Open returns an error then handle it
	if err != nil {
		log.Fatal("Cannot restore/open the json Defaults file", filename, " ", err.Error())
	}

	// read our opened jsonFile as a byte array.
	byteValue, _ := ioutil.ReadAll(jsonFile)

	var forRestore []*DefaultsDB

	err = json.Unmarshal(byteValue, &forRestore)

	// fill up Map_DefaultsDBID_DefaultsDB
	for _, defaultsDB := range forRestore {

		defaultsDB_ID_atBackupTime := defaultsDB.ID
		defaultsDB.ID = 0
		query := backRepoDefaults.db.Create(defaultsDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
		backRepoDefaults.Map_DefaultsDBID_DefaultsDB[defaultsDB.ID] = defaultsDB
		BackRepoDefaultsid_atBckpTime_newID[defaultsDB_ID_atBackupTime] = defaultsDB.ID
	}

	if err != nil {
		log.Fatal("Cannot restore/unmarshall json Defaults file", err.Error())
	}
}

// RestorePhaseTwo uses all map BackRepo<Defaults>id_atBckpTime_newID
// to compute new index
func (backRepoDefaults *BackRepoDefaultsStruct) RestorePhaseTwo() {

	for _, defaultsDB := range backRepoDefaults.Map_DefaultsDBID_DefaultsDB {

		// next line of code is to avert unused variable compilation error
		_ = defaultsDB

		// insertion point for reindexing pointers encoding
		// reindexing Scaling field
		if defaultsDB.ScalingID.Int64 != 0 {
			defaultsDB.ScalingID.Int64 = int64(BackRepoScalingid_atBckpTime_newID[uint(defaultsDB.ScalingID.Int64)])
			defaultsDB.ScalingID.Valid = true
		}

		// reindexing Concert_score field
		if defaultsDB.Concert_scoreID.Int64 != 0 {
			defaultsDB.Concert_scoreID.Int64 = int64(BackRepoEmptyid_atBckpTime_newID[uint(defaultsDB.Concert_scoreID.Int64)])
			defaultsDB.Concert_scoreID.Valid = true
		}

		// reindexing Appearance field
		if defaultsDB.AppearanceID.Int64 != 0 {
			defaultsDB.AppearanceID.Int64 = int64(BackRepoAppearanceid_atBckpTime_newID[uint(defaultsDB.AppearanceID.Int64)])
			defaultsDB.AppearanceID.Valid = true
		}

		// reindexing Music_font field
		if defaultsDB.Music_fontID.Int64 != 0 {
			defaultsDB.Music_fontID.Int64 = int64(BackRepoEmpty_fontid_atBckpTime_newID[uint(defaultsDB.Music_fontID.Int64)])
			defaultsDB.Music_fontID.Valid = true
		}

		// reindexing Word_font field
		if defaultsDB.Word_fontID.Int64 != 0 {
			defaultsDB.Word_fontID.Int64 = int64(BackRepoEmpty_fontid_atBckpTime_newID[uint(defaultsDB.Word_fontID.Int64)])
			defaultsDB.Word_fontID.Valid = true
		}

		// update databse with new index encoding
		query := backRepoDefaults.db.Model(defaultsDB).Updates(*defaultsDB)
		if query.Error != nil {
			log.Fatal(query.Error)
		}
	}

}

// BackRepoDefaults.ResetReversePointers commits all staged instances of Defaults to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoDefaults *BackRepoDefaultsStruct) ResetReversePointers(backRepo *BackRepoStruct) (Error error) {

	for idx, defaults := range backRepoDefaults.Map_DefaultsDBID_DefaultsPtr {
		backRepoDefaults.ResetReversePointersInstance(backRepo, idx, defaults)
	}

	return
}

func (backRepoDefaults *BackRepoDefaultsStruct) ResetReversePointersInstance(backRepo *BackRepoStruct, idx uint, defaults *models.Defaults) (Error error) {

	// fetch matching defaultsDB
	if defaultsDB, ok := backRepoDefaults.Map_DefaultsDBID_DefaultsDB[idx]; ok {
		_ = defaultsDB // to avoid unused variable error if there are no reverse to reset

		// insertion point for reverse pointers reset
		// end of insertion point for reverse pointers reset
	}

	return
}

// this field is used during the restauration process.
// it stores the ID at the backup time and is used for renumbering
var BackRepoDefaultsid_atBckpTime_newID map[uint]uint
